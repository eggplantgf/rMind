# rMind: 비접촉 면접 반응 분석 플랫폼

**rMind**는 영상 기반의 rPPG(remote photoplethysmography) 기술을 활용하여  
면접 상황에서 사용자의 생리적 반응을 비접촉 방식으로 분석하고 시각화하는 모바일 플랫폼입니다.  
심박수(BPM), 눈 깜빡임, 신체 움직임 등 **비언어적 신호**를 정량적으로 표현하여,  
면접 준비 과정에서 자신의 긴장도 및 반응을 객관적으로 파악할 수 있도록 지원합니다.

---

## 🎯 주요 기능

- 📝 **회원가입 및 로그인**: 이메일 기반 사용자 계정 생성 및 로그인 기능 구현
- 📷 **면접 영상 업로드**: 모바일 앱에서 사전 녹화된 면접 영상을 서버로 업로드
- 💓 **심박수(rPPG) 분석**: 얼굴 영상의 G 채널 변화를 기반으로 실시간 BPM 추정
- 👁️ **눈 깜빡임 분석**: 프레임 단위로 눈 감김 여부를 감지하여 시간별 깜빡임 빈도 시각화
- 🧍 **신체 움직임 분석**: dlib 얼굴 랜드마크를 이용하여 움직임 급변 감지 및 스코어화
- 📊 **시각화 결과 제공**: 분석 결과를 BPM 곡선, 눈 깜빡임 그래프, 움직임 점수 그래프로 제공

---

## ⚙️ 사용 기술

- **프론트엔드**: Flutter, Dart
- **백엔드**: FastAPI, Python
- **신호 처리**: OpenCV, NumPy, SciPy
- **얼굴 인식**: Haar Cascade, Dlib
- **rPPG 알고리즘**: CHROM, POS, ICA
- **심박수 추정 기법**: 푸리에 변환, 웨이블릿 분석, 피크 간 분석
- **데이터 처리 포맷**: CSV(신호 저장), PNG(결과 이미지 시각화)
